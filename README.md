# _PYSPARK PIPELINE_

#### By _**BriChavez**_

#### _Using Pyspark, this application will import a csv, clean it, and read to parquet_

## Technologies Used

* _Python_
* _Pyspark_
* _SparkSessions_

## Description

_First we upload and read a csv. Then, using set specifications, we will set schema, add new columns, and query the data. Last we will write the new dataframe into a parquet file_

## Setup/Installation Requirements

* _Visit https://github.com/BriChavez/sparktest2_
* _Using the terminal git remote clone the repo_
* _Set up a virtual environment and pip install -r requirements.txt_
* _Make a folder called data and run the code from set_up.sh while in it._
* _Go back to the main directory and run python3.7 main.py 

## Known Bugs

* _None_

## License

_If you have any questions, comments, suggestions, feel free to reach out at brianchavez@gmail.com_

Copyright (c) _June 2022_ _BriChavez_